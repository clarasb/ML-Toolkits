{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e20755ed31a7d277",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# General functioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0755c068719de7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "The algorithm is divided into two main parts:\n",
    "\n",
    "1. data_preparation.py -> Selecting the gaps: cut temporal and spatial data of a given variable from a xcube data cube and if requested create artificial gaps.\n",
    "2. gapfilling.py -> Fill in the gaps: estimate the values in these gaps by creating a model for each pixel.\n",
    "\n",
    "Each time 'EarthSystemDataCubeS3(ds_name, variable, dimensions, artificial_gaps, actual_matrix).get_data()' is executed, a new directory is created in 'application_results/'.\n",
    "Inside this directory the class \"GapDataset\" creates 2 subdirectories. \n",
    "In 'History/' all samples except one matrix from the specified time period and area are stored with the corresponding values of the specified variable for each pixel.\n",
    "The only exception is the randomly selected actual array where the artificial gaps are created.\n",
    "If artificial gaps should be created, the arrays with the artificial gaps are stored in 'GapImitation/' with different gap sizes in each array.\n",
    "Two other arrays are stored in the corresponding subdirectory 'application_result/.../'.\n",
    "The first is the current matrix mentioned earlier and the other is an array with the extra data e.g. corresponding land cover class values for each value in the matrix.\n",
    "The extra matrix can be used as a predictor configuration for the gap filling process.\n",
    "\n",
    "In the second step the execution of 'SupportVectorRegressionGapfill(ds_name, hyperparameters, predictor).gapfill()' creates the subdirectory 'Results/'.\n",
    "For each gap the values will be estimated. \n",
    "The average difference of the estimated value and the actual value (only available at artificial gaps) of each gap will be calculated as well as the mean absolute error based on cross validation. \n",
    "The filled arrays will be stored in 'Results/' subdirectory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1be913410a58df0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Data\n",
    "\n",
    "The currently used data is from the [xcube](https://xcube.readthedocs.io/en/latest/installation.html) dataset.\n",
    "This gapfilling algorithms works currently for a Earth System Data Cube but its functionality can be adapted for other gapfilling use cases by inheriting from the GapDataset class.\n",
    "For more information about the xcube data, follow the link.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28b946dacc656a1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Parameters\n",
    "\n",
    "### GapDataset class\n",
    "\n",
    "#### Subclasses\n",
    "- a subclass needs to be selected to perform the data preparation algorithm -> it selected the origin of the dataset, other datacubes as inherited classes as well\n",
    "- EarthSystemDataCubeS3\n",
    "\n",
    "#### ds_name\n",
    "- specify the name of the dataset -> a new directory with this name will be created in 'application_results/' - if a directory with this name already exists, it will be overwritten\n",
    "- DEFAULT: 'Test123'\n",
    "- other options: \n",
    "    - free choice - no restriction for the naming convention\n",
    "\n",
    "#### variable\n",
    "- variable that will be estimated. More possible variables from the Earth System Data Cube can be found [here](https://deepesdl.readthedocs.io/en/latest/datasets/ESDC/#variable-list)\n",
    "- DEFAULT: 'land_surface_temperature'\n",
    "- other options:\n",
    "    - 'air_temperature_2m'\n",
    "\n",
    "#### dimensions\n",
    "- dimensions of the data cube that will be sliced e.g. lat, lon, times\n",
    "- DEFAULT: dimensions = {'lat': (54, 48), 'lon': (6, 15), 'times': (datetime.date(2008, 11, 1), datetime.date(2008, 12, 31))}\n",
    "- other options:\n",
    "    - free choice - global range: lat = (90, -90), lon = (-180, 180), times: total range from 1979-2018, but most values are recorded from 2002-2011\n",
    "\n",
    "#### artificial_gaps\n",
    "- list of artificial gaps that can be created -> the gapfilling algorithm performs on artificial gaps if they are stated; if this parameter is None, it estimates real gaps in the matrix\n",
    "- DEFAULT: None\n",
    "- other options\n",
    "    - free choice - total range for each element from 0-1, e.g. [0.001, 0.01, 0.1, 0.25, 0.5, 0.75]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd70ba521cb12e93",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Gapfiller class\n",
    "\n",
    "#### Subclasses\n",
    "- a subclass needs to be selected to perform the gapfilling algorithm - other learning algorithms such as Random Forest or other regressions can be added as inherited classes as well\n",
    "- SupportVectorRegressionGapfill\n",
    "\n",
    "#### ds_name\n",
    "- same as the name for the GapDataset class -> otherwise no directory will be found and the gapfilling algorithm cannot perform\n",
    "- DEFAULT: 'Test123'\n",
    "- other options: \n",
    "    - free choice - but it should have the name of an existing directory in 'application_results/'\n",
    "\n",
    "#### hyperparameters\n",
    "- strategies for configuring hyperparameters\n",
    "- DEFAULT: 'RandomGridSearch' - random grid search\n",
    "- other options:\n",
    "    - 'FullGridSearch' - full grid search\n",
    "    - 'Custom' - custom settings according to the scikit-learn syntax that can be changed in the 'learning_function'-method - current settings: **params = {'kernel': 'linear', 'gamma': 'scale', 'C': 1000, 'epsilon': 1}\n",
    "\n",
    "#### predictor\n",
    "- strategies for selecting predictors\n",
    "- DEFAULT: 'RandomPoints' - randomly selected 100 points in the matrix - if less than 100 points with values in the metric, all non-gap values will be used as predictors; if less than 50 pixel have known values, interpolation is used to estimate the gaps\n",
    "- other options:\n",
    "    - 'AllPoints' - all known values -> runtime can be very big\n",
    "    - 'LCC' - the 40 closest pixels from the same land cover class (e.g. mixed forest) as the gap will be used as predictors - if there are less than 40 pixels from the same land cover class, the strategy changes to 'RandomPoints'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c8997b8b6ed2c6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Observations and recommendations (so far)\n",
    "\n",
    "In terms of runtime and accuracy, 'RandomGridSearch' works best for configuring hyperparameters and 'LCC' for selecting predictors; 'RandomPoints' or other categorical variables might be suitable options to estimate the gaps, depending on the use case.\n",
    "Since a model is created for each gap pixel, the runtime increases linearly proportional to the number of gaps, while the accuracy deteriorates only slightly.\n",
    "For the number of training samples, no more than 40-100 arrays need to be cut from the respective area - since the recordings in the data cube occur every 8 days and the runtime increases with the number of training samples, 1-2 years could be sufficient as a time period. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c87741d36226a5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Example with added artificial gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feef2bf8db3f241e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T18:14:26.688277118Z",
     "start_time": "2023-09-28T18:14:00.718268705Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GermanyNB_artificial_gaps {'time': 46, 'lat': 72, 'lon': 108}\n",
      "No of files: 46\n",
      "1 / 46\n",
      "2 / 46\n",
      "3 / 46\n",
      "4 / 46\n",
      "5 / 46\n",
      "6 / 46\n",
      "7 / 46\n",
      "8 / 46\n",
      "9 / 46\n",
      "10 / 46\n",
      "11 / 46\n",
      "12 / 46\n",
      "13 / 46\n",
      "14 / 46\n",
      "15 / 46\n",
      "16 / 46\n",
      "17 / 46\n",
      "18 / 46\n",
      "19 / 46\n",
      "20 / 46\n",
      "21 / 46\n",
      "22 / 46\n",
      "23 / 46\n",
      "24 / 46\n",
      "25 / 46\n",
      "26 / 46\n",
      "27 / 46\n",
      "28 / 46\n",
      "29 / 46\n",
      "30 / 46\n",
      "31 / 46\n",
      "32 / 46\n",
      "33 / 46\n",
      "34 / 46\n",
      "35 / 46\n",
      "36 / 46\n",
      "37 / 46\n",
      "38 / 46\n",
      "39 / 46\n",
      "40 / 46\n",
      "41 / 46\n",
      "42 / 46\n",
      "43 / 46\n",
      "44 / 46\n",
      "45 / 46\n",
      "46 / 46\n",
      "Structure {'complete': 0, 'empty': 0, 'gaps': 46}\n",
      "date: 2008-04-10\n",
      "real gap size:  63 %\n",
      "Exception: gap size 50.0 % -> contains not enough non-NaN values. No array with imitated gaps was created.\n",
      "Exception: gap size 75.0 % -> contains not enough non-NaN values. No array with imitated gaps was created.\n",
      "7 arrays with gaps were created!\n",
      "runtime: 134.86\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from xcube.core.store import new_data_store\n",
    "\n",
    "# add path, if mltools not installed\n",
    "import sys\n",
    "sys.path.append('../mltools')\n",
    "\n",
    "from mltools.gap_dataset import EarthSystemDataCubeS3\n",
    "from mltools.gap_filling import SupportVectorRegressionGapfill\n",
    "\n",
    "\n",
    "# Directory name\n",
    "ds_name = 'GermanyNB_artificial_gaps'\n",
    "# Variable that will be estimated e.g. 'land_surface_temperature' or 'air_temperature_2m'\n",
    "variable = 'land_surface_temperature'\n",
    "# Dimension values of the datacube, e.g. Latitude and longitude and of the area and times.\n",
    "# Global range: lat = (90, -90), lon = (-180, 180)\n",
    "dimensions = {\n",
    "    'lat': (54, 48),\n",
    "    'lon': (6, 15),\n",
    "    'times': (datetime.date(2008, 1, 1), datetime.date(2008, 12, 31))\n",
    "}\n",
    "# List of artificial gaps that will be created\n",
    "# if no artificial gaps should be created, the gapfilling algorithms will perform on real gaps\n",
    "# options: None or list of artificial gap sizes e.g. [0.001, 0.01, 0.1, 0.25, 0.5, 0.75]\n",
    "artificial_gaps = [0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.25, 0.5, 0.75]\n",
    "# Speficy whether the actual matrix will be chosen random or is from a specific file.\n",
    "# Options: 'Random' or datetime.date of the specific file e.g. datetime.date(2008, 12, 14)\n",
    "actual_matrix = 'Random'\n",
    "\n",
    "data_store = new_data_store(\"s3\", root=\"esdl-esdc-v2.1.1\", storage_options=dict(anon=True))\n",
    "dataset = data_store.open_data('esdc-8d-0.083deg-184x270x270-2.1.1.zarr')\n",
    "# Select the variable of interest from the dataset\n",
    "ds = dataset[variable]\n",
    "\n",
    "EarthSystemDataCubeS3(ds, ds_name, dimensions, artificial_gaps, actual_matrix).get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78acd0341eef054a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T18:21:54.145260955Z",
     "start_time": "2023-09-28T18:15:45.334713175Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date: 2008-04-10 \n",
      "gap size: 0.1 % -> 7 pixel \n",
      "training pictures: 45\n",
      "MAE actual: 1.045\n",
      "MAE cross validation: 0.897\n",
      "runtime: 0.17 seconds \n",
      "\n",
      "date: 2008-04-10 \n",
      "gap size: 0.5 % -> 38 pixel \n",
      "training pictures: 45\n",
      "MAE actual: 1.191\n",
      "MAE cross validation: 1.03\n",
      "runtime: 0.78 seconds \n",
      "\n",
      "date: 2008-04-10 \n",
      "gap size: 1.0 % -> 77 pixel \n",
      "training pictures: 45\n",
      "MAE actual: 1.544\n",
      "MAE cross validation: 1.212\n",
      "runtime: 1.48 seconds \n",
      "\n",
      "date: 2008-04-10 \n",
      "gap size: 5.0 % -> 388 pixel \n",
      "training pictures: 45\n",
      "MAE actual: 1.511\n",
      "MAE cross validation: 1.095\n",
      "runtime: 7.28 seconds \n",
      "\n",
      "date: 2008-04-10 \n",
      "gap size: 10.0 % -> 777 pixel \n",
      "training pictures: 45\n",
      "MAE actual: 1.595\n",
      "MAE cross validation: 1.053\n",
      "runtime: 14.71 seconds \n",
      "\n",
      "date: 2008-04-10 \n",
      "gap size: 20.0 % -> 1555 pixel \n",
      "training pictures: 45\n",
      "MAE actual: 1.715\n",
      "MAE cross validation: 1.215\n",
      "runtime: 30.88 seconds \n",
      "\n",
      "date: 2008-04-10 \n",
      "gap size: 25.0 % -> 1944 pixel \n",
      "training pictures: 45\n",
      "MAE actual: 1.787\n",
      "MAE cross validation: 1.306\n",
      "runtime: 39.56 seconds \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Directory name based on the input name in 'GapDataset'\n",
    "ds_name = 'GermanyNB_artificial_gaps'\n",
    "# Choose hyperparameter settings. Options: 'RandomGridSearch' | 'FullGridSearch' | 'Custom'\n",
    "hyperparameters = \"RandomGridSearch\"\n",
    "# Choose the predictor type. Options: 'AllPoints' | 'LCC' | 'RandomPoints'\n",
    "predictor = \"LCC\"\n",
    "# Create an instance of the SupportVectorRegressionGapfill class with the specified settings\n",
    "SVR_Gapfiller = SupportVectorRegressionGapfill(ds_name=ds_name, hyperparameters=hyperparameters, predictor=predictor)\n",
    "# Perform the gap filling using the chosen settings\n",
    "SVR_Gapfiller.gapfill()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd09804d57ec264",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Example without artificial gaps where the algorithm estimates real gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69dce6d04aef2279",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T18:27:05.878837787Z",
     "start_time": "2023-09-28T18:26:43.156116001Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GermanyNB_with_real_gaps {'time': 46, 'lat': 72, 'lon': 108}\n",
      "No of files: 46\n",
      "1 / 46\n",
      "2 / 46\n",
      "3 / 46\n",
      "4 / 46\n",
      "5 / 46\n",
      "6 / 46\n",
      "7 / 46\n",
      "8 / 46\n",
      "9 / 46\n",
      "10 / 46\n",
      "11 / 46\n",
      "12 / 46\n",
      "13 / 46\n",
      "14 / 46\n",
      "15 / 46\n",
      "16 / 46\n",
      "17 / 46\n",
      "18 / 46\n",
      "19 / 46\n",
      "20 / 46\n",
      "21 / 46\n",
      "22 / 46\n",
      "23 / 46\n",
      "24 / 46\n",
      "25 / 46\n",
      "26 / 46\n",
      "27 / 46\n",
      "28 / 46\n",
      "29 / 46\n",
      "30 / 46\n",
      "31 / 46\n",
      "32 / 46\n",
      "33 / 46\n",
      "34 / 46\n",
      "35 / 46\n",
      "36 / 46\n",
      "37 / 46\n",
      "38 / 46\n",
      "39 / 46\n",
      "40 / 46\n",
      "41 / 46\n",
      "42 / 46\n",
      "43 / 46\n",
      "44 / 46\n",
      "45 / 46\n",
      "46 / 46\n",
      "Structure {'complete': 0, 'empty': 0, 'gaps': 46}\n",
      "date: 2008-12-14\n",
      "real gap size:  21 %\n",
      "runtime: 145.51\n"
     ]
    }
   ],
   "source": [
    "# Directory name\n",
    "ds_name = 'GermanyNB_with_real_gaps'\n",
    "# Variable that will be estimated e.g. 'land_surface_temperature' or 'air_temperature_2m'\n",
    "variable = 'land_surface_temperature'\n",
    "# Dimension values of the datacube, e.g. Latitude and longitude and of the area and times.\n",
    "# Global range: lat = (90, -90), lon = (-180, 180)\n",
    "dimensions = {\n",
    "    'lat': (54, 48),\n",
    "    'lon': (6, 15),\n",
    "    'times': (datetime.date(2008, 1, 1), datetime.date(2008, 12, 31))\n",
    "}\n",
    "# List of artificial gaps that will be created\n",
    "# if no artificial gaps should be created, the gapfilling algorithms will perform on real gaps\n",
    "# options: None or list of artificial gap sizes e.g. [0.001, 0.01, 0.1, 0.25, 0.5, 0.75]\n",
    "artificial_gaps = None\n",
    "# Speficy whether the actual matrix will be chosen random or is from a specific file.\n",
    "# Options: 'Random' or datetime.date of the specific file e.g. datetime.date(2008, 12, 14)\n",
    "actual_matrix = datetime.date(2008, 12, 14)\n",
    "\n",
    "data_store = new_data_store(\"s3\", root=\"esdl-esdc-v2.1.1\", storage_options=dict(anon=True))\n",
    "dataset = data_store.open_data('esdc-8d-0.083deg-184x270x270-2.1.1.zarr')\n",
    "# Select the variable of interest from the dataset\n",
    "ds = dataset[variable]\n",
    "\n",
    "EarthSystemDataCubeS3(ds, ds_name, dimensions, artificial_gaps, actual_matrix).get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea013510dd60069",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T18:28:08.468727657Z",
     "start_time": "2023-09-28T18:27:11.122304573Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date: 2008-12-14 \n",
      "gap size: 20.8 % -> 1617 pixel \n",
      "training pictures: 45\n",
      "MAE actual: Could not be calculated as no true actual matrix available.\n",
      "MAE cross validation: Could not be calculated as interpolation was partly used.\n",
      "runtime: 25.00 seconds \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Directory name based on the input name in 'GapDataset'\n",
    "ds_name = 'GermanyNB_with_real_gaps'\n",
    "# Choose hyperparameter settings. Options: 'RandomGridSearch' | 'FullGridSearch' | 'Custom'\n",
    "hyperparameters = \"RandomGridSearch\"\n",
    "# Choose the predictor type. Options: 'AllPoints' | 'LCC' | 'RandomPoints'\n",
    "predictor = \"LCC\"\n",
    "# Create an instance of the SupportVectorRegressionGapfill class with the specified settings\n",
    "SVR_Gapfiller = SupportVectorRegressionGapfill(ds_name=ds_name, hyperparameters=hyperparameters, predictor=predictor)\n",
    "# Perform the gap filling using the chosen settings\n",
    "SVR_Gapfiller.gapfill()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3547984e03dcc024",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
